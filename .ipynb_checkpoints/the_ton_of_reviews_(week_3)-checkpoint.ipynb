{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iH7_5mJpGWE0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\mi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\mi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\mi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pickle\n",
    "!pip install imblearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwzxBUMOQKoo"
   },
   "source": [
    "Выгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "f1Xa4HXcGkM4"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None, names=['text', 'Id'])\n",
    "data_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t', index_col='Id')\n",
    "data_id = pd.read_csv('products_sentiment_sample_submission.csv', sep=',', index_col='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjaY8ja4HHZM",
    "outputId": "857eb27e-f690-46c9-9c81-de5c166e8f17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "0     726\n",
       "1    1274\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.groupby(by='Id')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "PVmzBiD8KvSK"
   },
   "outputs": [],
   "source": [
    "def cls_pipeline(vect, cls):\n",
    "    return Pipeline([\n",
    "                   ('vectorizer', vect),\n",
    "                   ('classifier', cls)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "hmfMFwAkOpnC"
   },
   "outputs": [],
   "source": [
    "train_data = data_train['text']\n",
    "train_label = data_train['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LpQmdsngQ4G"
   },
   "source": [
    "Baseline признаки на частотах слов и логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EwXaAp_QNoZC"
   },
   "outputs": [],
   "source": [
    "cv_result_bl = cross_val_score(cls_pipeline(CountVectorizer(), LogisticRegression(class_weight='balanced')),train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7Q9MRGpPZV-",
    "outputId": "c80eb7a8-ae55-4fa5-b851-102d96c5ec52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy baseline: 0.7645000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy baseline: {cv_result_bl.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-3vXKXfgkvc"
   },
   "source": [
    "Удалим стоп слова "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "yVnxyDxMPo0Y"
   },
   "outputs": [],
   "source": [
    "cv_result_sw = cross_val_score(cls_pipeline(CountVectorizer(stop_words='english'), \n",
    "                                            LogisticRegression()),\n",
    "                                            train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwwHjhRGhXze",
    "outputId": "dcbd0764-9d5c-453b-df74-28d21e824529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy without stop words: 0.748\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy without stop words: {cv_result_sw.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsJavW2Qh1kA"
   },
   "source": [
    "Качество не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1Y5ftEUilYq"
   },
   "source": [
    "Используем tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "xeH-fUZUhlfo"
   },
   "outputs": [],
   "source": [
    "cv_result_tfidf = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
    "                                              LogisticRegression()),\n",
    "                                              train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GeCq6zPiRPK",
    "outputId": "5e4aba90-97d9-478c-b6e9-0705dc64c11a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy tfidf :0.766\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy tfidf :{cv_result_tfidf.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgIUjVQNi2o8"
   },
   "source": [
    "Попробуем использовать LinearSVC, SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pvWdkLDhibQs"
   },
   "outputs": [],
   "source": [
    "linear_model_list = [SGDClassifier(), LinearSVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "gHI365EpjXTy"
   },
   "outputs": [],
   "source": [
    "cv_other_linear_models = []\n",
    "for model in linear_model_list:\n",
    "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
    "                                          model),\n",
    "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
    "  cv_other_linear_models.append(cv_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbMHAcW1kv0y",
    "outputId": "b9177631-7681-4cd6-8654-4d3a4f7f2284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy SGDClassifier: 0.753\n",
      "Mean accuracy LinearSVC: 0.7689999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy SGDClassifier: {cv_other_linear_models[0]}\")\n",
    "print(f\"Mean accuracy LinearSVC: {cv_other_linear_models[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gzVr6xTmT88"
   },
   "source": [
    "Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "LziXA-nTlElW"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qemfCf7Km7oE"
   },
   "outputs": [],
   "source": [
    "cv_forests = []\n",
    "for forest in [RandomForestClassifier(), GradientBoostingClassifier()]:\n",
    "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
    "                                          forest),\n",
    "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
    "  cv_forests.append(cv_result.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2thIeySyn5mC",
    "outputId": "016b1d85-a04a-45e4-f93c-fe84f6da2acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy RFC: 0.7314999999999999\n",
      "Mean accuracy XGB: 0.7304999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy RFC: {cv_forests[0]}\")\n",
    "print(f\"Mean accuracy XGB: {cv_forests[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqCg5WvloKQo"
   },
   "source": [
    "Как видно все модели по умолчанию выдают примерно одинаковое качесвто около 0.75\n",
    "Возьмем одну из них, например, логистическую регрессиб и поработаем с признаковым пространством."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI6hl-jb2y3N"
   },
   "source": [
    "Ипользуем n_gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "aLLsUCkLo0_2"
   },
   "outputs": [],
   "source": [
    "cv_result_ngram = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(1,3)), \n",
    "                                            LogisticRegression()),\n",
    "                               train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sg2HCKd5p83i",
    "outputId": "5fe136f9-a3cd-4c3e-e4b3-afa3e26cecec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy with ngram for 1 to 3: 0.7645\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean accuracy with ngram for 1 to 3: {cv_result_ngram.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62hj_1KF23za"
   },
   "source": [
    "Буквенные n_gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "JoEaPtc0qPz6"
   },
   "outputs": [],
   "source": [
    "cv_result_ngramchar = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(3,6), analyzer='char'), \n",
    "                                            LogisticRegression()),\n",
    "                               train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-A8nd8Awrm_M",
    "outputId": "0ef10ac2-451b-4069-eafd-3be27e6151b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy with ngram char for 1 to 3: 0.771\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean accuracy with ngram char for 1 to 3: {cv_result_ngramchar.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGkCHZDj29zl"
   },
   "source": [
    "Дополнительные преобразования после векторизации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "G-x9WDCavcqe"
   },
   "outputs": [],
   "source": [
    "def cls_pipeline_transform(vect, trans, cls):\n",
    "  return Pipeline([\n",
    "                   ('vectorizer', vect),\n",
    "                   ('transformer', trans),\n",
    "                   ('classifier', cls)\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5oUBr5d49Xt",
    "outputId": "efa54fd9-87e5-4fb7-ed80-ae8c7fd5ee60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3973)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_data = CountVectorizer().fit_transform(train_data)\n",
    "vect_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vkVw2X15Zcr"
   },
   "source": [
    "Всего получается около 4000 признаков попробуем провести понижение размерности признакового пространства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "0R4IglXK9meg"
   },
   "outputs": [],
   "source": [
    "cv_result_trans = cross_val_score(cls_pipeline_transform(CountVectorizer(),\n",
    "                                                 TruncatedSVD(n_components=1000),\n",
    "                                                 LogisticRegression()),\n",
    "                               train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tRNeBgHl5nb",
    "outputId": "99014df3-ab4b-4a53-9576-06b9072ee37f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7659999999999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_trans.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYoYsE3-uNVW"
   },
   "source": [
    "Попробуем построение частотных n-грамм с tfidf преобразованием и LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "-dRNcj5OBD6g"
   },
   "outputs": [],
   "source": [
    "cv_result_countt = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
    "                                                          TfidfTransformer(),\n",
    "                                                          LinearSVC()),\n",
    "                                                          train_data, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8GKKhcfBzyY",
    "outputId": "60476dee-4dc7-4545-dba4-00b03d5f4b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_countt.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycnVQFwXuhhS"
   },
   "source": [
    "Получилось наилучшее качество из всех рассмотренных вариантов\n",
    "\n",
    "Далее будем использовать этот pipeline кроме отдельных случаев\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T_Tci9ef98a"
   },
   "source": [
    "Попробуем трюк с добавление частицы не в начало слова, след. функкция реализует это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "qDkkhWe1wmbS"
   },
   "outputs": [],
   "source": [
    "def add_neg(review):\n",
    "  neg_chars = {\"dont\", \"nt\", \"n't\", \"doesnt\", \"does'nt\", \"'t\", \"not\", \"no\"}\n",
    "  words = review.split(' ')\n",
    "  new_review = []\n",
    "  i = 0\n",
    "  while i < len(words):\n",
    "    if words[i] in neg_chars:\n",
    "      new_review.append(words[i] + \"_\" + words[i+1] )\n",
    "      i+= 2\n",
    "    else:\n",
    "      new_review.append(words[i])\n",
    "      i+= 1\n",
    "  return ' '.join(new_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "vqJCUEgAzMmw"
   },
   "outputs": [],
   "source": [
    "train_neg = train_data.apply(add_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "yXS2gBvuzOZb"
   },
   "outputs": [],
   "source": [
    "cv_result_addneg = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
    "                                                          TfidfTransformer(),\n",
    "                                                          LinearSVC()),\n",
    "                                                          train_neg, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oppHqzbr1OvI",
    "outputId": "3d575ddd-00fb-4f24-b46d-3514ad66e731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7825\n"
     ]
    }
   ],
   "source": [
    "print(cv_result_addneg.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiQ1P55kq6XA"
   },
   "source": [
    "Представим текст в виде векторов word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "NLIuj0Q1k62K"
   },
   "outputs": [],
   "source": [
    "all_stopwords = gensim.parsing.preprocessing.STOPWORDS # стоп слова "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHvXv0b9iydE",
    "outputId": "ddb02b57-476a-420f-8f37-6f0754a0c676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [2, ., 10,000, 640x480, pictures, .]\n",
       "1       [downloaded, trial, version, associates, ez, f...\n",
       "2       [wrt54g, plus, hga7t, perfect, solution, need,...\n",
       "3       [dont, especially, like, music, files, unstruc...\n",
       "4       [cheapie, pail, ..., worked, ok, opening, devi...\n",
       "                              ...                        \n",
       "1995    [speaker, phone, quality, good, ,, poping, 512...\n",
       "1996                        [\", movies, \", 5, seconds, .]\n",
       "1997                                   [overall, like, .]\n",
       "1998    [began, taking, pics, soon, got, camera, amaze...\n",
       "1999      [reading, instructions, ,, 's, hard, figure, .]\n",
       "Name: text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = train_data.apply(lambda x: [word for word in x.split() if word not in all_stopwords]) #токенизация предложений и фильтрация по стоп словам\n",
    "list_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61-PQ-791ScB",
    "outputId": "f27ba7e2-8e28-4e4a-d422-4182557c491d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7819, 20540)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# построение и обучение модели векторизации слов\n",
    "model_w2v = gensim.models.Word2Vec(size=1000, min_count=10)\n",
    "model_w2v.build_vocab(list_words)\n",
    "model_w2v.train(list_words,total_examples=model_w2v.corpus_count, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "osiwqPEnoes0"
   },
   "outputs": [],
   "source": [
    "# функция которая переводит весь текст в один вектор по векторам слов усредняя их\n",
    "def creat_vect_text(model, words_list):\n",
    "  all_vect = np.array([model.wv[word] for word in words_list if word in model.wv])\n",
    "  return all_vect.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "oJI_aWRgpreg",
    "outputId": "2a8472a2-8469-4031-ccc4-c3970f28c230"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>-0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>-0.000794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.001373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.001482</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>-0.000222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.000077 -0.000400  0.000388  0.000795  0.000295  0.000162 -0.000147   \n",
       "1 -0.000092 -0.000075  0.000143  0.000579  0.000256  0.000326 -0.000093   \n",
       "2 -0.000214 -0.000152  0.000354  0.000209  0.000174  0.000240 -0.000242   \n",
       "3 -0.000114 -0.000012  0.000222  0.000565  0.000066  0.000438 -0.000172   \n",
       "4  0.000086 -0.000067  0.000048  0.000432  0.000360  0.000137  0.000014   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0  0.001262  0.000962 -0.001580  ... -0.000127 -0.001365 -0.000443 -0.000681   \n",
       "1  0.000803  0.000308 -0.000757  ... -0.000053 -0.000741 -0.000365 -0.000226   \n",
       "2  0.000681  0.000287 -0.000794  ... -0.000172 -0.000856 -0.000203 -0.000088   \n",
       "3  0.000888  0.000568 -0.001373  ... -0.000064 -0.001482 -0.000499 -0.000365   \n",
       "4  0.000715  0.000148 -0.000810  ... -0.000086 -0.000730 -0.000119 -0.000201   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0 -0.001418  0.000743 -0.000876 -0.000801  0.001088 -0.000640  \n",
       "1 -0.000846  0.000288 -0.000431 -0.000497  0.000632 -0.000442  \n",
       "2 -0.000825  0.000122 -0.000466 -0.000314  0.000599 -0.000099  \n",
       "3 -0.001117  0.000317 -0.001090 -0.000652  0.001130 -0.000472  \n",
       "4 -0.000676  0.000413 -0.000401 -0.000228  0.000610 -0.000222  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vect_data = [creat_vect_text(model_w2v, text) for text in list_words]\n",
    "data_text_vect = pd.DataFrame(train_vect_data)\n",
    "data_text_vect.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "KF4yPS7v-2RQ"
   },
   "outputs": [],
   "source": [
    "cv_result_vect_lr = cross_val_score(LogisticRegression(),data_text_vect, train_label, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5YKNC_kLkN-",
    "outputId": "3a6122b9-baa6-4ce7-a25c-7de7da360742"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369999999999999"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_vect_lr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgE8RF--1oq6"
   },
   "source": [
    "Балансировка классов будстрапом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbvLG7ysxSLL",
    "outputId": "d674ed4e-c5c8-4766-86dc-bc50e3fc7f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274\n",
      "1274\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "X = train_data.to_numpy().reshape(-1,1)\n",
    "X_b, y_b = RandomOverSampler().fit_resample(X, train_label)\n",
    "print(np.sum(y_b==1))\n",
    "print(np.sum(y_b==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAKq-3HY0gUk",
    "outputId": "002afe50-2943-4bc0-b6f7-033ecc658ca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724742863746677"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_balance = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
    "                                                          TfidfTransformer(),\n",
    "                                                          LinearSVC()),\n",
    "                                                          X_b.reshape(1,X_b.shape[0])[0], y_b, scoring='accuracy', cv=5)\n",
    "\n",
    "cv_result_balance.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBx_-4ME3Bma"
   },
   "source": [
    "Лучший вариант с качеством выше 0.8. Обучим pipeline на всех данных и посмотрим на качество тестовых данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHrjxhUD3JZD",
    "outputId": "ef70d659-15ca-4603-98e2-eca5094e6781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
       "                ('transformer', TfidfTransformer()),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cls = cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
    "                                   TfidfTransformer(),\n",
    "                                   LinearSVC())\n",
    "model_cls.fit(X_b.reshape(1,X_b.shape[0])[0], y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KSLIsgv4LOP",
    "outputId": "4a1117ca-7b03-4e03-9d50-80b5700a31f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy: {metrics.accuracy_score(y_b, model_cls.predict(X_b.reshape(1,X_b.shape[0])[0]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi2m4L2l2xBV"
   },
   "source": [
    "Прогноз на тестовой выборке\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "DAYG7sV65WFR",
    "outputId": "3691bebc-0a17-483e-d99c-4ac1cfa08ae7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y\n",
       "Id   \n",
       "0   1\n",
       "1   0\n",
       "2   1\n",
       "3   1\n",
       "4   0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model_cls.predict(data_test['text'])\n",
    "data_id['y'] = predicted\n",
    "data_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Q3mC8thF8fCk"
   },
   "outputs": [],
   "source": [
    "data_id.to_csv('sample_sabmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE3PZesdB55X"
   },
   "source": [
    "Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "                      ('trans', TfidfTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "the ton of reviews (week_3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
