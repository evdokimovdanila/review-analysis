{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "the ton of reviews (week_3).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH7_5mJpGWE0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import NMF, TruncatedSVD\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import gensim\n",
        "import numpy as np"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwzxBUMOQKoo"
      },
      "source": [
        "Выгружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Xa4HXcGkM4"
      },
      "source": [
        "data_train = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None, names=['text', 'Id'])\n",
        "data_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t', index_col='Id')\n",
        "data_id = pd.read_csv('products_sentiment_sample_submission.csv', sep=',', index_col='Id')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjaY8ja4HHZM",
        "outputId": "2ba8a1d1-5621-4f9b-e67a-97eccfc66866"
      },
      "source": [
        "data_train.groupby(by='Id')['text'].count()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id\n",
              "0     726\n",
              "1    1274\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVmzBiD8KvSK"
      },
      "source": [
        "def cls_pipeline(vect, cls):\n",
        "  return Pipeline([\n",
        "                   ('vectorizer', vect),\n",
        "                   ('classifier', cls)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmfMFwAkOpnC"
      },
      "source": [
        "train_data = data_train['text']\n",
        "train_label = data_train['Id']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LpQmdsngQ4G"
      },
      "source": [
        "Baseline признаки на частотах слов и логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXaAp_QNoZC"
      },
      "source": [
        "cv_result_bl = cross_val_score(cls_pipeline(CountVectorizer(), LogisticRegression(class_weight='balanced')),train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Q9MRGpPZV-",
        "outputId": "de16e459-2fd8-43ae-8beb-632c7e64f93e"
      },
      "source": [
        "print(f\"Mean accuracy baseline: {cv_result_bl.mean()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy baseline: 0.7645000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-3vXKXfgkvc"
      },
      "source": [
        "Удалим стоп слова "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVnxyDxMPo0Y"
      },
      "source": [
        "cv_result_sw = cross_val_score(cls_pipeline(CountVectorizer(stop_words='english'), \n",
        "                                            LogisticRegression()),\n",
        "                                            train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwwHjhRGhXze",
        "outputId": "fe86eccc-ca28-4eb0-81de-3784ebbe1e0d"
      },
      "source": [
        "print(f\"Mean accuracy without stop words: {cv_result_sw.mean()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy without stop words: 0.748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsJavW2Qh1kA"
      },
      "source": [
        "Качество не изменилось"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Y5ftEUilYq"
      },
      "source": [
        "Используем tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeH-fUZUhlfo"
      },
      "source": [
        "cv_result_tfidf = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                              LogisticRegression()),\n",
        "                                              train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GeCq6zPiRPK",
        "outputId": "374c1495-3448-491d-9903-0cd57396de0c"
      },
      "source": [
        "print(f\"Mean accuracy tfidf :{cv_result_tfidf.mean()}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy tfidf :0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIUjVQNi2o8"
      },
      "source": [
        "Попробуем использовать LinearSVC, SGDClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvWdkLDhibQs"
      },
      "source": [
        "linear_model_list = [SGDClassifier(), LinearSVC()]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHI365EpjXTy"
      },
      "source": [
        "cv_other_linear_models = []\n",
        "for model in linear_model_list:\n",
        "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                          model),\n",
        "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
        "  cv_other_linear_models.append(cv_result.mean())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbMHAcW1kv0y",
        "outputId": "4e28fc56-f74f-46ff-c601-8360df9a842c"
      },
      "source": [
        "print(f\"Mean accuracy SGDClassifier: {cv_other_linear_models[0]}\")\n",
        "print(f\"Mean accuracy LinearSVC: {cv_other_linear_models[1]}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy SGDClassifier: 0.7555000000000001\n",
            "Mean accuracy LinearSVC: 0.7689999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzVr6xTmT88"
      },
      "source": [
        "Решающие деревья"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziXA-nTlElW"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qemfCf7Km7oE"
      },
      "source": [
        "cv_forests = []\n",
        "for forest in [RandomForestClassifier(), GradientBoostingClassifier()]:\n",
        "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                          forest),\n",
        "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
        "  cv_forests.append(cv_result.mean())\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2thIeySyn5mC",
        "outputId": "71f71110-d8e7-4529-8277-f1d642f0f52a"
      },
      "source": [
        "print(f\"Mean accuracy RFC: {cv_forests[0]}\")\n",
        "print(f\"Mean accuracy XGB: {cv_forests[1]}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy RFC: 0.7335\n",
            "Mean accuracy XGB: 0.7275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqCg5WvloKQo"
      },
      "source": [
        "Как видно все модели по умолчанию выдают примерно одинаковое качесвто около 0.75\n",
        "Возьмем одну из них, например, логистическую регрессиб и поработаем с признаковым пространством."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI6hl-jb2y3N"
      },
      "source": [
        "Ипользуем n_gramm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLLsUCkLo0_2"
      },
      "source": [
        "cv_result_ngram = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(1,3)), \n",
        "                                            LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg2HCKd5p83i",
        "outputId": "9c13e1ae-03f3-45ee-f444-6da1e70d89e0"
      },
      "source": [
        "print(f\"mean accuracy with ngram for 1 to 3: {cv_result_ngram.mean()}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean accuracy with ngram for 1 to 3: 0.7645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62hj_1KF23za"
      },
      "source": [
        "Буквенные n_gramm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoEaPtc0qPz6"
      },
      "source": [
        "cv_result_ngramchar = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(3,6), analyzer='char'), \n",
        "                                            LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A8nd8Awrm_M",
        "outputId": "4a0be604-7dd3-4d55-8092-4bb443681809"
      },
      "source": [
        "print(f\"mean accuracy with ngram char for 1 to 3: {cv_result_ngramchar.mean()}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean accuracy with ngram char for 1 to 3: 0.771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGkCHZDj29zl"
      },
      "source": [
        "Дополнительные преобразования после векторизации\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-x9WDCavcqe"
      },
      "source": [
        "def cls_pipeline_transform(vect, trans, cls):\n",
        "  return Pipeline([\n",
        "                   ('vectorizer', vect),\n",
        "                   ('transformer', trans),\n",
        "                   ('classifier', cls)\n",
        "                  ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5oUBr5d49Xt",
        "outputId": "9b62dc48-9555-453d-9cbe-c42bec0bedb8"
      },
      "source": [
        "vect_data = CountVectorizer().fit_transform(train_data)\n",
        "vect_data.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 3973)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkVw2X15Zcr"
      },
      "source": [
        "Всего получается около 4000 признаков попробуем провести понижение размерности признакового пространства."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R4IglXK9meg"
      },
      "source": [
        "cv_result_trans = cross_val_score(cls_pipeline_transform(CountVectorizer(),\n",
        "                                                 TruncatedSVD(n_components=1000),\n",
        "                                                 LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tRNeBgHl5nb",
        "outputId": "80a24828-11cb-4e4b-da85-40234400446b"
      },
      "source": [
        "cv_result_trans.mean()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7670000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYoYsE3-uNVW"
      },
      "source": [
        "Попробуем построение частотных n-грамм с tfidf преобразованием и LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRNcj5OBD6g"
      },
      "source": [
        "cv_result_countt = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8GKKhcfBzyY",
        "outputId": "a76a46bf-5006-46dd-d436-f07c0abedc22"
      },
      "source": [
        "cv_result_countt.mean()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycnVQFwXuhhS"
      },
      "source": [
        "Получилось наилучшее качество из всех рассмотренных вариантов\n",
        "\n",
        "Далее будем использовать этот pipeline кроме отдельных случаев\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T_Tci9ef98a"
      },
      "source": [
        "Попробуем трюк с добавление частицы не в начало слова, след. функкция реализует это."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDkkhWe1wmbS"
      },
      "source": [
        "def add_neg(review):\n",
        "  neg_chars = {\"dont\", \"nt\", \"n't\", \"doesnt\", \"does'nt\", \"'t\", \"not\", \"no\"}\n",
        "  words = review.split(' ')\n",
        "  new_review = []\n",
        "  i = 0\n",
        "  while i < len(words):\n",
        "    if words[i] in neg_chars:\n",
        "      new_review.append(words[i] + \"_\" + words[i+1] )\n",
        "      i+= 2\n",
        "    else:\n",
        "      new_review.append(words[i])\n",
        "      i+= 1\n",
        "  return ' '.join(new_review)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqJCUEgAzMmw"
      },
      "source": [
        "train_neg = train_data.apply(add_neg)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXS2gBvuzOZb"
      },
      "source": [
        "cv_result_addneg = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          train_neg, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oppHqzbr1OvI",
        "outputId": "ad2214aa-5f60-494e-8e8f-b2a1d1532cb3"
      },
      "source": [
        "print(cv_result_addneg.mean())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQ1P55kq6XA"
      },
      "source": [
        "Представим текст в виде векторов word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLIuj0Q1k62K"
      },
      "source": [
        "all_stopwords = gensim.parsing.preprocessing.STOPWORDS # стоп слова "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHvXv0b9iydE",
        "outputId": "cd7fbd4b-ff44-4860-e0b6-d6be29504271"
      },
      "source": [
        "list_words = train_data.apply(lambda x: [word for word in x.split() if word not in all_stopwords]) #токенизация предложений и фильтрация по стоп словам\n",
        "list_words"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                    [2, ., 10,000, 640x480, pictures, .]\n",
              "1       [downloaded, trial, version, associates, ez, f...\n",
              "2       [wrt54g, plus, hga7t, perfect, solution, need,...\n",
              "3       [dont, especially, like, music, files, unstruc...\n",
              "4       [cheapie, pail, ..., worked, ok, opening, devi...\n",
              "                              ...                        \n",
              "1995    [speaker, phone, quality, good, ,, poping, 512...\n",
              "1996                        [\", movies, \", 5, seconds, .]\n",
              "1997                                   [overall, like, .]\n",
              "1998    [began, taking, pics, soon, got, camera, amaze...\n",
              "1999      [reading, instructions, ,, 's, hard, figure, .]\n",
              "Name: text, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61-PQ-791ScB",
        "outputId": "fc6e1837-0833-4316-b302-e9ac758e2ca0"
      },
      "source": [
        "# построение и обучение модели векторизации слов\n",
        "model_w2v = gensim.models.Word2Vec(size=1000, min_count=10)\n",
        "model_w2v.build_vocab(list_words)\n",
        "model_w2v.train(list_words,total_examples=model_w2v.corpus_count, epochs=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7814, 20540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osiwqPEnoes0"
      },
      "source": [
        "# функция которая переводит весь текст в один вектор по векторам слов усредняя их\n",
        "def creat_vect_text(model, words_list):\n",
        "  all_vect = np.array([model.wv[word] for word in words_list if word in model.wv])\n",
        "  return all_vect.mean(axis=0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "oJI_aWRgpreg",
        "outputId": "2201d050-9ef2-4304-ea32-b25d1056095a"
      },
      "source": [
        "train_vect_data = [creat_vect_text(model_w2v, text) for text in list_words]\n",
        "data_text_vect = pd.DataFrame(train_vect_data)\n",
        "data_text_vect.head()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>960</th>\n",
              "      <th>961</th>\n",
              "      <th>962</th>\n",
              "      <th>963</th>\n",
              "      <th>964</th>\n",
              "      <th>965</th>\n",
              "      <th>966</th>\n",
              "      <th>967</th>\n",
              "      <th>968</th>\n",
              "      <th>969</th>\n",
              "      <th>970</th>\n",
              "      <th>971</th>\n",
              "      <th>972</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>979</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000143</td>\n",
              "      <td>-0.000556</td>\n",
              "      <td>-0.000825</td>\n",
              "      <td>-0.001271</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>0.000903</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.001710</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>-0.000802</td>\n",
              "      <td>-0.000451</td>\n",
              "      <td>-0.000274</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>-0.001603</td>\n",
              "      <td>-0.000403</td>\n",
              "      <td>-0.000285</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.001031</td>\n",
              "      <td>-0.002059</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>-0.000119</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.001456</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.001535</td>\n",
              "      <td>-0.001456</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>-0.000161</td>\n",
              "      <td>-0.000270</td>\n",
              "      <td>-0.001063</td>\n",
              "      <td>-0.000693</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>-0.000808</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>-0.000433</td>\n",
              "      <td>-0.000919</td>\n",
              "      <td>-0.001015</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>-0.001530</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.000812</td>\n",
              "      <td>-0.000949</td>\n",
              "      <td>-0.000261</td>\n",
              "      <td>0.000859</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000629</td>\n",
              "      <td>-0.000622</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>-0.001510</td>\n",
              "      <td>-0.000643</td>\n",
              "      <td>-0.001335</td>\n",
              "      <td>0.001903</td>\n",
              "      <td>-0.001689</td>\n",
              "      <td>-0.000137</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>-0.001151</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>-0.000951</td>\n",
              "      <td>-0.001266</td>\n",
              "      <td>-0.000386</td>\n",
              "      <td>-0.001024</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.001061</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.001858</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.001541</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>-0.001011</td>\n",
              "      <td>-0.000126</td>\n",
              "      <td>-0.000147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000122</td>\n",
              "      <td>-0.000319</td>\n",
              "      <td>-0.000234</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>-0.000385</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>-0.000854</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>-0.000152</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>-0.001046</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000713</td>\n",
              "      <td>-0.000385</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>-0.000994</td>\n",
              "      <td>-0.000808</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>-0.000185</td>\n",
              "      <td>-0.000333</td>\n",
              "      <td>-0.000723</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000266</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-0.000679</td>\n",
              "      <td>-0.000869</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>-0.000546</td>\n",
              "      <td>-0.000882</td>\n",
              "      <td>0.000696</td>\n",
              "      <td>-0.000434</td>\n",
              "      <td>-0.000152</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000918</td>\n",
              "      <td>-0.000648</td>\n",
              "      <td>-0.000336</td>\n",
              "      <td>-0.000666</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>-0.000942</td>\n",
              "      <td>-0.000164</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>-0.000645</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000713</td>\n",
              "      <td>-0.000188</td>\n",
              "      <td>-0.000475</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000789</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>-0.001095</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>-0.000020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000192</td>\n",
              "      <td>-0.000339</td>\n",
              "      <td>-0.000180</td>\n",
              "      <td>-0.000739</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>-0.000363</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>-0.000168</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>-0.000326</td>\n",
              "      <td>-0.000240</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>-0.000603</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>-0.000686</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>-0.000158</td>\n",
              "      <td>-0.000481</td>\n",
              "      <td>-0.000108</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000323</td>\n",
              "      <td>-0.000276</td>\n",
              "      <td>-0.000464</td>\n",
              "      <td>-0.000496</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.000967</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>-0.000308</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>-0.000305</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>-0.000839</td>\n",
              "      <td>-0.000312</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>-0.000804</td>\n",
              "      <td>-0.000173</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.000347</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>-0.000472</td>\n",
              "      <td>-0.000589</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>-0.000450</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>-0.000946</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000865</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>-0.000020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000352</td>\n",
              "      <td>-0.000756</td>\n",
              "      <td>-0.000471</td>\n",
              "      <td>-0.001123</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>-0.000527</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.000444</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.001270</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>-0.000378</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000566</td>\n",
              "      <td>-0.001609</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>-0.000142</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>-0.001013</td>\n",
              "      <td>0.000453</td>\n",
              "      <td>0.001295</td>\n",
              "      <td>-0.001445</td>\n",
              "      <td>-0.000944</td>\n",
              "      <td>-0.000043</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.000338</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>-0.000865</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000425</td>\n",
              "      <td>-0.000602</td>\n",
              "      <td>-0.000830</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>0.000882</td>\n",
              "      <td>-0.001116</td>\n",
              "      <td>-0.001386</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>-0.000539</td>\n",
              "      <td>-0.000073</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>-0.000430</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>-0.001047</td>\n",
              "      <td>-0.000323</td>\n",
              "      <td>-0.000979</td>\n",
              "      <td>0.001599</td>\n",
              "      <td>-0.001427</td>\n",
              "      <td>-0.000364</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000887</td>\n",
              "      <td>-0.000758</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>-0.000487</td>\n",
              "      <td>-0.001065</td>\n",
              "      <td>-0.000598</td>\n",
              "      <td>-0.000755</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>-0.001714</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>0.000205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000160</td>\n",
              "      <td>-0.000145</td>\n",
              "      <td>-0.000333</td>\n",
              "      <td>-0.000520</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>-0.000512</td>\n",
              "      <td>-0.000133</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.000698</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-0.000173</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>-0.000017</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>-0.000814</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000741</td>\n",
              "      <td>-0.000559</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>-0.000839</td>\n",
              "      <td>-0.000478</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>-0.000518</td>\n",
              "      <td>-0.000055</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>-0.000529</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000176</td>\n",
              "      <td>-0.000236</td>\n",
              "      <td>-0.000342</td>\n",
              "      <td>-0.000374</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>-0.000671</td>\n",
              "      <td>-0.000789</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>-0.000289</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>-0.000618</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.000610</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>-0.000814</td>\n",
              "      <td>-0.000233</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>-0.000517</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>-0.000445</td>\n",
              "      <td>-0.000517</td>\n",
              "      <td>-0.000119</td>\n",
              "      <td>-0.000556</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>-0.000925</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.000736</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-0.000164</td>\n",
              "      <td>-0.000021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       997       998       999\n",
              "0  0.000143 -0.000556 -0.000825  ... -0.001011 -0.000126 -0.000147\n",
              "1  0.000122 -0.000319 -0.000234  ... -0.000653 -0.000120 -0.000020\n",
              "2  0.000192 -0.000339 -0.000180  ... -0.000420 -0.000064 -0.000020\n",
              "3  0.000352 -0.000756 -0.000471  ... -0.001004 -0.000124  0.000205\n",
              "4  0.000160 -0.000145 -0.000333  ... -0.000438 -0.000164 -0.000021\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF4yPS7v-2RQ"
      },
      "source": [
        "cv_result_vect_lr = cross_val_score(LogisticRegression(),data_text_vect, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5YKNC_kLkN-",
        "outputId": "b18db7ab-298c-4b0a-fc3b-edb96485e80d"
      },
      "source": [
        "cv_result_vect_lr.mean()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6369999999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgE8RF--1oq6"
      },
      "source": [
        "Балансировка классов будстрапом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbvLG7ysxSLL",
        "outputId": "c6dbe2c3-734d-4b1c-ebf6-6186226eecf1"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X = train_data.to_numpy().reshape(-1,1)\n",
        "X_b, y_b = RandomOverSampler().fit_sample(X, train_label)\n",
        "print(np.sum(y_b==1))\n",
        "print(np.sum(y_b==0))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1274\n",
            "1274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAKq-3HY0gUk",
        "outputId": "beffeda3-e972-4e60-8509-f2678bf41bcd"
      },
      "source": [
        "cv_result_balance = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          X_b.reshape(1,X_b.shape[0])[0], y_b, scoring='accuracy', cv=5)\n",
        "\n",
        "cv_result_balance.mean()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8771817096190146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBx_-4ME3Bma"
      },
      "source": [
        "Лучший вариант с качеством выше 0.8. Обучим pipeline на всех данных и посмотрим на качество тестовых данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHrjxhUD3JZD",
        "outputId": "50513755-776d-4b8e-88b5-aa225da94caf"
      },
      "source": [
        "model_cls = cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                   TfidfTransformer(),\n",
        "                                   LinearSVC())\n",
        "model_cls.fit(X_b.reshape(1,X_b.shape[0])[0], y_b)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('transformer',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KSLIsgv4LOP",
        "outputId": "f5b810f3-3de0-4741-83b0-2321d69a2dfd"
      },
      "source": [
        "print(f\"Mean accuracy: {metrics.accuracy_score(y_b, model_cls.predict(X_b.reshape(1,X_b.shape[0])[0]))}\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "SsL2eYkM48du",
        "outputId": "2fcafd4e-58d8-4758-9431-8be7a7aba03c"
      },
      "source": [
        "data_test"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>so , why the small digital elph , rather than ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3/4 way through the first disk we played on it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>better for the zen micro is outlook compatibil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6 . play gameboy color games on it with goboy .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>i took perfect care of this player and still i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>it 's a very intuitive program .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>the only drawback is the viewfinder is slightl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>it films 10 second video , for crying out loud .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>everything shines of quality .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "Id                                                    \n",
              "0    so , why the small digital elph , rather than ...\n",
              "1    3/4 way through the first disk we played on it...\n",
              "2    better for the zen micro is outlook compatibil...\n",
              "3      6 . play gameboy color games on it with goboy .\n",
              "4    likewise , i 've heard norton 2004 professiona...\n",
              "..                                                 ...\n",
              "495  i took perfect care of this player and still i...\n",
              "496                  it 's a very intuitive program . \n",
              "497  the only drawback is the viewfinder is slightl...\n",
              "498   it films 10 second video , for crying out loud .\n",
              "499                     everything shines of quality .\n",
              "\n",
              "[500 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DAYG7sV65WFR",
        "outputId": "67bc10ff-9fcf-47d1-b084-1ada0ca6d9b7"
      },
      "source": [
        "data_id"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     y\n",
              "Id    \n",
              "0    0\n",
              "1    1\n",
              "2    0\n",
              "3    1\n",
              "4    0\n",
              "..  ..\n",
              "495  1\n",
              "496  0\n",
              "497  1\n",
              "498  0\n",
              "499  1\n",
              "\n",
              "[500 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmHHrfWd5X3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}