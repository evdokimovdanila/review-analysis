{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "the ton of reviews (week_3).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH7_5mJpGWE0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import NMF, TruncatedSVD\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import gensim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwzxBUMOQKoo"
      },
      "source": [
        "Выгружаем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Xa4HXcGkM4"
      },
      "source": [
        "data_train = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None, names=['text', 'Id'])\n",
        "data_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t', index_col='Id')\n",
        "data_id = pd.read_csv('products_sentiment_sample_submission.csv', sep=',', index_col='Id')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjaY8ja4HHZM",
        "outputId": "857eb27e-f690-46c9-9c81-de5c166e8f17"
      },
      "source": [
        "data_train.groupby(by='Id')['text'].count()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id\n",
              "0     726\n",
              "1    1274\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVmzBiD8KvSK"
      },
      "source": [
        "def cls_pipeline(vect, cls):\n",
        "  return Pipeline([\n",
        "                   ('vectorizer', vect),\n",
        "                   ('classifier', cls)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmfMFwAkOpnC"
      },
      "source": [
        "train_data = data_train['text']\n",
        "train_label = data_train['Id']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LpQmdsngQ4G"
      },
      "source": [
        "Baseline признаки на частотах слов и логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXaAp_QNoZC"
      },
      "source": [
        "cv_result_bl = cross_val_score(cls_pipeline(CountVectorizer(), LogisticRegression(class_weight='balanced')),train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Q9MRGpPZV-",
        "outputId": "c80eb7a8-ae55-4fa5-b851-102d96c5ec52"
      },
      "source": [
        "print(f\"Mean accuracy baseline: {cv_result_bl.mean()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy baseline: 0.7645000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-3vXKXfgkvc"
      },
      "source": [
        "Удалим стоп слова "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVnxyDxMPo0Y"
      },
      "source": [
        "cv_result_sw = cross_val_score(cls_pipeline(CountVectorizer(stop_words='english'), \n",
        "                                            LogisticRegression()),\n",
        "                                            train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwwHjhRGhXze",
        "outputId": "dcbd0764-9d5c-453b-df74-28d21e824529"
      },
      "source": [
        "print(f\"Mean accuracy without stop words: {cv_result_sw.mean()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy without stop words: 0.748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsJavW2Qh1kA"
      },
      "source": [
        "Качество не изменилось"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Y5ftEUilYq"
      },
      "source": [
        "Используем tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeH-fUZUhlfo"
      },
      "source": [
        "cv_result_tfidf = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                              LogisticRegression()),\n",
        "                                              train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GeCq6zPiRPK",
        "outputId": "5e4aba90-97d9-478c-b6e9-0705dc64c11a"
      },
      "source": [
        "print(f\"Mean accuracy tfidf :{cv_result_tfidf.mean()}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy tfidf :0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIUjVQNi2o8"
      },
      "source": [
        "Попробуем использовать LinearSVC, SGDClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvWdkLDhibQs"
      },
      "source": [
        "linear_model_list = [SGDClassifier(), LinearSVC()]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHI365EpjXTy"
      },
      "source": [
        "cv_other_linear_models = []\n",
        "for model in linear_model_list:\n",
        "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                          model),\n",
        "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
        "  cv_other_linear_models.append(cv_result.mean())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbMHAcW1kv0y",
        "outputId": "b9177631-7681-4cd6-8654-4d3a4f7f2284"
      },
      "source": [
        "print(f\"Mean accuracy SGDClassifier: {cv_other_linear_models[0]}\")\n",
        "print(f\"Mean accuracy LinearSVC: {cv_other_linear_models[1]}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy SGDClassifier: 0.758\n",
            "Mean accuracy LinearSVC: 0.7689999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzVr6xTmT88"
      },
      "source": [
        "Решающие деревья"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziXA-nTlElW"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qemfCf7Km7oE"
      },
      "source": [
        "cv_forests = []\n",
        "for forest in [RandomForestClassifier(), GradientBoostingClassifier()]:\n",
        "  cv_result = cross_val_score(cls_pipeline(TfidfVectorizer(), \n",
        "                                          forest),\n",
        "                                          train_data, train_label, scoring='accuracy', cv=5)\n",
        "  cv_forests.append(cv_result.mean())\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2thIeySyn5mC",
        "outputId": "016b1d85-a04a-45e4-f93c-fe84f6da2acc"
      },
      "source": [
        "print(f\"Mean accuracy RFC: {cv_forests[0]}\")\n",
        "print(f\"Mean accuracy XGB: {cv_forests[1]}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy RFC: 0.7304999999999999\n",
            "Mean accuracy XGB: 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqCg5WvloKQo"
      },
      "source": [
        "Как видно все модели по умолчанию выдают примерно одинаковое качесвто около 0.75\n",
        "Возьмем одну из них, например, логистическую регрессиб и поработаем с признаковым пространством."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI6hl-jb2y3N"
      },
      "source": [
        "Ипользуем n_gramm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLLsUCkLo0_2"
      },
      "source": [
        "cv_result_ngram = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(1,3)), \n",
        "                                            LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg2HCKd5p83i",
        "outputId": "5fe136f9-a3cd-4c3e-e4b3-afa3e26cecec"
      },
      "source": [
        "print(f\"mean accuracy with ngram for 1 to 3: {cv_result_ngram.mean()}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean accuracy with ngram for 1 to 3: 0.7645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62hj_1KF23za"
      },
      "source": [
        "Буквенные n_gramm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoEaPtc0qPz6"
      },
      "source": [
        "cv_result_ngramchar = cross_val_score(cls_pipeline(CountVectorizer(ngram_range=(3,6), analyzer='char'), \n",
        "                                            LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A8nd8Awrm_M",
        "outputId": "0ef10ac2-451b-4069-eafd-3be27e6151b6"
      },
      "source": [
        "print(f\"mean accuracy with ngram char for 1 to 3: {cv_result_ngramchar.mean()}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean accuracy with ngram char for 1 to 3: 0.771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGkCHZDj29zl"
      },
      "source": [
        "Дополнительные преобразования после векторизации\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-x9WDCavcqe"
      },
      "source": [
        "def cls_pipeline_transform(vect, trans, cls):\n",
        "  return Pipeline([\n",
        "                   ('vectorizer', vect),\n",
        "                   ('transformer', trans),\n",
        "                   ('classifier', cls)\n",
        "                  ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5oUBr5d49Xt",
        "outputId": "efa54fd9-87e5-4fb7-ed80-ae8c7fd5ee60"
      },
      "source": [
        "vect_data = CountVectorizer().fit_transform(train_data)\n",
        "vect_data.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 3973)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkVw2X15Zcr"
      },
      "source": [
        "Всего получается около 4000 признаков попробуем провести понижение размерности признакового пространства."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R4IglXK9meg"
      },
      "source": [
        "cv_result_trans = cross_val_score(cls_pipeline_transform(CountVectorizer(),\n",
        "                                                 TruncatedSVD(n_components=1000),\n",
        "                                                 LogisticRegression()),\n",
        "                               train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tRNeBgHl5nb",
        "outputId": "99014df3-ab4b-4a53-9576-06b9072ee37f"
      },
      "source": [
        "cv_result_trans.mean()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYoYsE3-uNVW"
      },
      "source": [
        "Попробуем построение частотных n-грамм с tfidf преобразованием и LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRNcj5OBD6g"
      },
      "source": [
        "cv_result_countt = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          train_data, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8GKKhcfBzyY",
        "outputId": "60476dee-4dc7-4545-dba4-00b03d5f4b8a"
      },
      "source": [
        "cv_result_countt.mean()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycnVQFwXuhhS"
      },
      "source": [
        "Получилось наилучшее качество из всех рассмотренных вариантов\n",
        "\n",
        "Далее будем использовать этот pipeline кроме отдельных случаев\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T_Tci9ef98a"
      },
      "source": [
        "Попробуем трюк с добавление частицы не в начало слова, след. функкция реализует это."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDkkhWe1wmbS"
      },
      "source": [
        "def add_neg(review):\n",
        "  neg_chars = {\"dont\", \"nt\", \"n't\", \"doesnt\", \"does'nt\", \"'t\", \"not\", \"no\"}\n",
        "  words = review.split(' ')\n",
        "  new_review = []\n",
        "  i = 0\n",
        "  while i < len(words):\n",
        "    if words[i] in neg_chars:\n",
        "      new_review.append(words[i] + \"_\" + words[i+1] )\n",
        "      i+= 2\n",
        "    else:\n",
        "      new_review.append(words[i])\n",
        "      i+= 1\n",
        "  return ' '.join(new_review)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqJCUEgAzMmw"
      },
      "source": [
        "train_neg = train_data.apply(add_neg)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXS2gBvuzOZb"
      },
      "source": [
        "cv_result_addneg = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          train_neg, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oppHqzbr1OvI",
        "outputId": "3d575ddd-00fb-4f24-b46d-3514ad66e731"
      },
      "source": [
        "print(cv_result_addneg.mean())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQ1P55kq6XA"
      },
      "source": [
        "Представим текст в виде векторов word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLIuj0Q1k62K"
      },
      "source": [
        "all_stopwords = gensim.parsing.preprocessing.STOPWORDS # стоп слова "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHvXv0b9iydE",
        "outputId": "ddb02b57-476a-420f-8f37-6f0754a0c676"
      },
      "source": [
        "list_words = train_data.apply(lambda x: [word for word in x.split() if word not in all_stopwords]) #токенизация предложений и фильтрация по стоп словам\n",
        "list_words"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                    [2, ., 10,000, 640x480, pictures, .]\n",
              "1       [downloaded, trial, version, associates, ez, f...\n",
              "2       [wrt54g, plus, hga7t, perfect, solution, need,...\n",
              "3       [dont, especially, like, music, files, unstruc...\n",
              "4       [cheapie, pail, ..., worked, ok, opening, devi...\n",
              "                              ...                        \n",
              "1995    [speaker, phone, quality, good, ,, poping, 512...\n",
              "1996                        [\", movies, \", 5, seconds, .]\n",
              "1997                                   [overall, like, .]\n",
              "1998    [began, taking, pics, soon, got, camera, amaze...\n",
              "1999      [reading, instructions, ,, 's, hard, figure, .]\n",
              "Name: text, Length: 2000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61-PQ-791ScB",
        "outputId": "f27ba7e2-8e28-4e4a-d422-4182557c491d"
      },
      "source": [
        "# построение и обучение модели векторизации слов\n",
        "model_w2v = gensim.models.Word2Vec(size=1000, min_count=10)\n",
        "model_w2v.build_vocab(list_words)\n",
        "model_w2v.train(list_words,total_examples=model_w2v.corpus_count, epochs=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7814, 20540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osiwqPEnoes0"
      },
      "source": [
        "# функция которая переводит весь текст в один вектор по векторам слов усредняя их\n",
        "def creat_vect_text(model, words_list):\n",
        "  all_vect = np.array([model.wv[word] for word in words_list if word in model.wv])\n",
        "  return all_vect.mean(axis=0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "oJI_aWRgpreg",
        "outputId": "2a8472a2-8469-4031-ccc4-c3970f28c230"
      },
      "source": [
        "train_vect_data = [creat_vect_text(model_w2v, text) for text in list_words]\n",
        "data_text_vect = pd.DataFrame(train_vect_data)\n",
        "data_text_vect.head()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>960</th>\n",
              "      <th>961</th>\n",
              "      <th>962</th>\n",
              "      <th>963</th>\n",
              "      <th>964</th>\n",
              "      <th>965</th>\n",
              "      <th>966</th>\n",
              "      <th>967</th>\n",
              "      <th>968</th>\n",
              "      <th>969</th>\n",
              "      <th>970</th>\n",
              "      <th>971</th>\n",
              "      <th>972</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>979</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>-0.001600</td>\n",
              "      <td>0.001407</td>\n",
              "      <td>-0.001316</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.001150</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>-0.000422</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>-0.000471</td>\n",
              "      <td>-0.000318</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>-0.000478</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>-0.000045</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>-0.000078</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>8.473467e-07</td>\n",
              "      <td>0.001938</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>-0.001585</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>-0.000475</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>-0.000208</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>-0.000264</td>\n",
              "      <td>-0.000143</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>-0.000401</td>\n",
              "      <td>0.000479</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>-0.000790</td>\n",
              "      <td>-0.000280</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>0.000962</td>\n",
              "      <td>-0.000791</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>-0.000404</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>-0.000737</td>\n",
              "      <td>0.000958</td>\n",
              "      <td>-0.000952</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>-0.000924</td>\n",
              "      <td>-1.627725e-04</td>\n",
              "      <td>0.000620</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.000075</td>\n",
              "      <td>-0.001668</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.000520</td>\n",
              "      <td>0.000794</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>-0.000021</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>-0.001099</td>\n",
              "      <td>-0.000270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000367</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>-0.000748</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>-0.000085</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000083</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>-0.000167</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>-0.000058</td>\n",
              "      <td>-0.000073</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>-0.000510</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>-0.000312</td>\n",
              "      <td>2.544051e-04</td>\n",
              "      <td>0.001178</td>\n",
              "      <td>0.001081</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>-0.000105</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>-0.000347</td>\n",
              "      <td>-0.000488</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000568</td>\n",
              "      <td>-0.000167</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>-0.000324</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>-0.000198</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-0.000544</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>-0.000495</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>-0.000752</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>-0.000109</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>-0.000263</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>-0.000476</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>-0.000594</td>\n",
              "      <td>-2.578860e-04</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.000555</td>\n",
              "      <td>-0.000059</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>-0.000725</td>\n",
              "      <td>-0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000186</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>-0.000666</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.000775</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>-0.000707</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>-0.000181</td>\n",
              "      <td>-0.000188</td>\n",
              "      <td>-0.000257</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000082</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>-0.000208</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000522</td>\n",
              "      <td>-0.000085</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>-0.000132</td>\n",
              "      <td>9.989855e-05</td>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.001107</td>\n",
              "      <td>-0.000704</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>-0.000131</td>\n",
              "      <td>-0.000077</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>-0.000069</td>\n",
              "      <td>-0.000494</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000559</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>-0.000081</td>\n",
              "      <td>-0.000237</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>-0.000444</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000359</td>\n",
              "      <td>-0.000547</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>-0.000105</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>-0.000227</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>-0.000414</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>-0.000449</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>-0.000610</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.000248</td>\n",
              "      <td>3.672254e-05</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>-0.000548</td>\n",
              "      <td>-0.000202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>-0.001106</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>-0.000742</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.001197</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>-0.000164</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>-0.000277</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>-0.000101</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>-0.000154</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>1.134719e-04</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>0.001941</td>\n",
              "      <td>-0.001316</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001255</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>-0.000687</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001059</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-0.000193</td>\n",
              "      <td>-0.000100</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>-0.000323</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.000730</td>\n",
              "      <td>-0.001092</td>\n",
              "      <td>-0.000539</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>-0.000769</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>-0.000913</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>-0.000450</td>\n",
              "      <td>0.000461</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>-0.000760</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>-0.000922</td>\n",
              "      <td>-3.744143e-04</td>\n",
              "      <td>0.000568</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>-0.001494</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.000452</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.000108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000219</td>\n",
              "      <td>-0.000046</td>\n",
              "      <td>-0.000538</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>-0.000641</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>-0.000132</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>-0.000235</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>0.000551</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>-9.673397e-05</td>\n",
              "      <td>0.000691</td>\n",
              "      <td>0.000966</td>\n",
              "      <td>-0.000664</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000775</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>-0.000441</td>\n",
              "      <td>-0.000463</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000514</td>\n",
              "      <td>-0.000213</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>-0.000287</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>0.000404</td>\n",
              "      <td>-0.000482</td>\n",
              "      <td>-0.000242</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>-0.000529</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>-0.000214</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>-0.000382</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>-0.000549</td>\n",
              "      <td>-6.035989e-07</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>-0.000075</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>-0.000541</td>\n",
              "      <td>-0.000010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       997       998       999\n",
              "0  0.000391  0.000110 -0.001264  ...  0.000665 -0.001099 -0.000270\n",
              "1  0.000367  0.000190 -0.000832  ...  0.000467 -0.000725 -0.000300\n",
              "2  0.000186 -0.000067 -0.000666  ...  0.000250 -0.000548 -0.000202\n",
              "3  0.000399  0.000112 -0.001106  ...  0.000499 -0.000846 -0.000108\n",
              "4  0.000219 -0.000046 -0.000538  ...  0.000221 -0.000541 -0.000010\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF4yPS7v-2RQ"
      },
      "source": [
        "cv_result_vect_lr = cross_val_score(LogisticRegression(),data_text_vect, train_label, scoring='accuracy', cv=5)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5YKNC_kLkN-",
        "outputId": "3a6122b9-baa6-4ce7-a25c-7de7da360742"
      },
      "source": [
        "cv_result_vect_lr.mean()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6369999999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgE8RF--1oq6"
      },
      "source": [
        "Балансировка классов будстрапом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbvLG7ysxSLL",
        "outputId": "d674ed4e-c5c8-4766-86dc-bc50e3fc7f6b"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X = train_data.to_numpy().reshape(-1,1)\n",
        "X_b, y_b = RandomOverSampler().fit_sample(X, train_label)\n",
        "print(np.sum(y_b==1))\n",
        "print(np.sum(y_b==0))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1274\n",
            "1274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAKq-3HY0gUk",
        "outputId": "002afe50-2943-4bc0-b6f7-033ecc658ca4"
      },
      "source": [
        "cv_result_balance = cross_val_score(cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                                          TfidfTransformer(),\n",
        "                                                          LinearSVC()),\n",
        "                                                          X_b.reshape(1,X_b.shape[0])[0], y_b, scoring='accuracy', cv=5)\n",
        "\n",
        "cv_result_balance.mean()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8791417234870373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBx_-4ME3Bma"
      },
      "source": [
        "Лучший вариант с качеством выше 0.8. Обучим pipeline на всех данных и посмотрим на качество тестовых данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHrjxhUD3JZD",
        "outputId": "ef70d659-15ca-4603-98e2-eca5094e6781"
      },
      "source": [
        "model_cls = cls_pipeline_transform(CountVectorizer(ngram_range=(1,3)),\n",
        "                                   TfidfTransformer(),\n",
        "                                   LinearSVC())\n",
        "model_cls.fit(X_b.reshape(1,X_b.shape[0])[0], y_b)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('transformer',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KSLIsgv4LOP",
        "outputId": "4a1117ca-7b03-4e03-9d50-80b5700a31f1"
      },
      "source": [
        "print(f\"Mean accuracy: {metrics.accuracy_score(y_b, model_cls.predict(X_b.reshape(1,X_b.shape[0])[0]))}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi2m4L2l2xBV"
      },
      "source": [
        "Прогноз на тестовой выборке\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DAYG7sV65WFR",
        "outputId": "3691bebc-0a17-483e-d99c-4ac1cfa08ae7"
      },
      "source": [
        "predicted = model_cls.predict(data_test['text'])\n",
        "data_id['y'] = predicted\n",
        "data_id.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    y\n",
              "Id   \n",
              "0   1\n",
              "1   0\n",
              "2   1\n",
              "3   1\n",
              "4   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3mC8thF8fCk"
      },
      "source": [
        "data_id.to_csv('sample_sabmission.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE3PZesdB55X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}